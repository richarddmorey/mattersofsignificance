---
title: "Significance testing is misunderstood"
linktitle: "Misunderstood"
summary:
date: 2020-06-09T16:57:03+01:00
lastmod: 2020-06-09T16:57:03+01:00
draft: false  
type: docs  # Do not modify.
bibliography: "/Users/richard/Documents/Projects/mattersofsignificance/assets/bib/bibfile.bib"
csl: "/Users/richard/Documents/Projects/mattersofsignificance/assets/bib/apa.csl"
menu:
  significance:
    parent: Human factors
    weight: 1
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#outline-of-the-objection">Outline of the objection</a></li>
<li><a href="#potential-answers-to-the-objection">Potential answers to the objection</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="outline-of-the-objection" class="section level2">
<h2>Outline of the objection</h2>
<p>In spite of significance tests being ubiquitous in the sciences, many users of significance tests have a difficult time understanding them. Take, for example, the survey results reported by <span class="citation">Oakes (1986)</span>. Oakes asked 70 academic psychologists the following (p. 79):</p>
<blockquote>
<p>Suppose you have a treatment which you suspect may alter performance on a certain task. You compare the means of your control group and experimental groups (say 20 subjects in each sample). Further, suppose you use a simple independent means t test and your result is (<span class="math inline">\(t=2.7, d.f.=18, p=0.01\)</span>)[.] Please mark each of the statements below as ‘true’ or ‘false’.</p>
<ol style="list-style-type: decimal">
<li>You have absolutely disproved the null hypothesis (that there is no difference between the population means).</li>
<li>You have found the probability of the null hypothesis being true.</li>
<li>You have absolutely proved your experimental hypothesis (that there is a difference between the population means).</li>
<li>You can deduce the probability of the experimental hypothesis being true.</li>
<li>You know, if you decided to reject the null hypothesis, the probability that you are making the wrong decision.</li>
<li>You have a reliable experimental finding in the sense that if, hypothetically, the experiment were repeated a great number of times, you would obtain a significant result on 99% of occasions.</li>
</ol>
</blockquote>
<p>The responses given by the lecturers, researchers and post-graduate students are presented in the following table. <span class="math inline">\(f\)</span> represents the frequency at which respondents affirmed the corresponding statement as true.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#hkezeetsjb .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hkezeetsjb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hkezeetsjb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hkezeetsjb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hkezeetsjb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hkezeetsjb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hkezeetsjb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hkezeetsjb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hkezeetsjb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hkezeetsjb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hkezeetsjb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hkezeetsjb .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#hkezeetsjb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hkezeetsjb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hkezeetsjb .gt_from_md > :first-child {
  margin-top: 0;
}

#hkezeetsjb .gt_from_md > :last-child {
  margin-bottom: 0;
}

#hkezeetsjb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hkezeetsjb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#hkezeetsjb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hkezeetsjb .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#hkezeetsjb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hkezeetsjb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hkezeetsjb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hkezeetsjb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hkezeetsjb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#hkezeetsjb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hkezeetsjb .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#hkezeetsjb .gt_left {
  text-align: left;
}

#hkezeetsjb .gt_center {
  text-align: center;
}

#hkezeetsjb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hkezeetsjb .gt_font_normal {
  font-weight: normal;
}

#hkezeetsjb .gt_font_bold {
  font-weight: bold;
}

#hkezeetsjb .gt_font_italic {
  font-style: italic;
}

#hkezeetsjb .gt_super {
  font-size: 65%;
}

#hkezeetsjb .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="hkezeetsjb" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
  <thead class="gt_header">
    <tr>
      <th colspan="4" class="gt_heading gt_title gt_font_normal" style>Frequencies of ‘true’ responses</th>
    </tr>
    <tr>
      <th colspan="4" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>Oakes (1986), p. 80, Table 3.2.1.</th>
    </tr>
  </thead>
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Statement</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">$f$</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">%</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr>
      <td class="gt_row gt_center">(1)</td>
      <td class="gt_row gt_left">The null hypothesis is absolutely disproved</td>
      <td class="gt_row gt_right">1</td>
      <td class="gt_row gt_right">1.4</td>
    </tr>
    <tr>
      <td class="gt_row gt_center">(2)</td>
      <td class="gt_row gt_left">The probability of the null hypothesis has been found</td>
      <td class="gt_row gt_right">25</td>
      <td class="gt_row gt_right">35.7</td>
    </tr>
    <tr>
      <td class="gt_row gt_center">(3)</td>
      <td class="gt_row gt_left">The experimental hypothesis is absolutely proved</td>
      <td class="gt_row gt_right">4</td>
      <td class="gt_row gt_right">5.7</td>
    </tr>
    <tr>
      <td class="gt_row gt_center">(4)</td>
      <td class="gt_row gt_left">The probability of the experimental hypothesis can be deduced</td>
      <td class="gt_row gt_right">46</td>
      <td class="gt_row gt_right">65.7</td>
    </tr>
    <tr>
      <td class="gt_row gt_center">(5)</td>
      <td class="gt_row gt_left">The probability that the decision taken is wrong is known</td>
      <td class="gt_row gt_right">60</td>
      <td class="gt_row gt_right">85.7</td>
    </tr>
    <tr>
      <td class="gt_row gt_center">(6)</td>
      <td class="gt_row gt_left">Replications have a 0.99 probability of being significant</td>
      <td class="gt_row gt_right">42</td>
      <td class="gt_row gt_right">60.0</td>
    </tr>
  </tbody>
  
  
</table></div>
<p>The frequency of affirmation ranges from 1 to 60 out of 70. In truth, each of these statements is incorrect. Three of the 70 respondents (4%) correctly rejected all of the six false statements. For an explanation of why each of these are incorrect, see <span class="citation">Gigerenzer, Krauss, &amp; Vitouch (2004)</span>.</p>
<p><span class="citation">Falk &amp; Greenbaum (1995)</span> showed similar results among a student population even when those students were asked to read a paper focusing on the fallacies; <span class="citation">Haller &amp; Krauss (2002)</span> followed up with a similar survey specifically including working scientists, teachers of statistical methods, and students of statistics. As Haller and Krauss point out, misconceptions exist even in textbooks explaining significance testing.</p>
<p>Some common fallacies about significance tests include:</p>
<ul>
<li><em>“The <span class="math inline">\(p\)</span> value represents the probability that the null hypothesis is true.”</em> (see also statements 2 and 4 above) The <span class="math inline">\(p\)</span> value is the probability of obtaining evidence at least as discordant with the null hypothesis, assuming the null hypothesis were true. The probability is about the data, not the hypothesis.</li>
<li><em>“The <span class="math inline">\(p\)</span> value represents the probability that you’d be wrong if you decided that the null hypothesis were false.”</em> (see also statement 5 above) The <span class="math inline">\(p\)</span> value is an error probability, but only a) assuming the null hypothesis were true, and b) assuming you decided to take the strength of the evidence at hand as just decisive evidence against the null. It is a hypothetical error probability describing a decision procedure, not the probability that any given decision is in error.</li>
<li><em>“A low <span class="math inline">\(p\)</span> value means that the observed effect size is large, or that the result is important.”</em> For a given sample size, it is true that lower p values mean larger observed deviations from the null hypothesis (whatever it is), but small <span class="math inline">\(p\)</span> values coupled with large sample sizes may indicate small deviations from the null hypothesis that would be nevertheless be rare if the null hypothesis were true. Relatedly, a low <span class="math inline">\(p\)</span> does not indicate anything, by itself, about the importance of a result.</li>
<li><em>“The null hypothesis can be accepted as true on the basis of a large <span class="math inline">\(p\)</span> value.”</em> A large <span class="math inline">\(p\)</span> value indicates only that evidence against the null hypothesis as strong as what was found would not be unsurprising even if the null hypothesis were true. This would obviously be the case if, for instance, we had not tried very hard to find evidence against it. Just because the evidence doesn’t contradict a hypothesis does not mean that the hypothesis has solid evidence for it.</li>
</ul>
<p><span class="citation">Greenland et al. (2016)</span> present 25 misunderstandings related to significance testing and explain why each one is a fallacy.</p>
<p>Critics have also pointed to that judgments about research results are qualitatively different when they cross an arbitrary threshold like p&lt;.05. This so-called “cliff effect”, first described by <span class="citation">Rosenthal &amp; Gaito (1963)</span> and since replicated many times, has been taken as evidence that people impose a needlessly dichotomous interpretation on p values caused by the “statistical significance” below the threshold. Relatedly, <span class="citation">McShane &amp; Gal (2017)</span> show that statisticians are sensitive to statistical significance of a result even when it is inappropriate for the judgment at hand.</p>
<p>The sensitivity to statistical significance has caused many commentators to call replacing significance tests with confidence interval, likelihood, or Bayesian approaches. <span class="citation">Fidler &amp; Loftus (2009)</span> suggest that figures with means and error bars and/or confidence intervals should replace p values because “they lend themselves readily (in most cases) to graphical representation” and “do not necessarily entail a dichotomous decision”.</p>
<p>The dichotomization of evidence is closely related to another common fallacy of significance testing: the fallacy of “accepting” the null hypothesis on the basis of a high <span class="math inline">\(p\)</span> value. When <span class="math inline">\(p\)</span> is greater than the typical threshold of .05, researchers often opportunistically claim that a null hypothesis is true — rather than a failure to find strong evidence against it — even in case it has not been adequately tested (e.g., assessing the evidence for important assumptions with small sample sizes). The fallacy of acceptance is related the higher-order fallacy of believing that when one effect is significant and another is not, that there is evidence of a difference in the sizes of the effects. As <span class="citation">Gelman &amp; Stern (2006)</span> put it, the difference between “significant” and “not significant” is not itself statistically significant. <span class="citation">Nieuwenhuis, Forstmann, &amp; Wagenmakers (2011)</span> found the issue widespread in the neuroscience literature.</p>
<p>Amusingly, <a href="https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/">Aschwanden (2015)</a> asked researchers at a methods conference do explain p values, concluding that [“Not even scientists can easily explain <span class="math inline">\(P\)</span>-values”. Aschwanden ascribed the problem to the difficulty of the concepts underlying significance testing.</p>
<p>All of these these difficulties have led some to critique the use of significance testing itself. <span class="citation">Cumming (2014)</span>, for instance, says that such evidence “suggests that we should use estimation [e.g. confidence intervals] and avoid [null hypothesis significance testing]” and that significance testing “deludes us into thinking that any finding that meets the criterion of statistical significance is true and does not require replication.”</p>
<p>Some journal editors have used the researchers’ apparent misunderstandings to discourage or ban reports of statistical significance tests. <span class="citation">Lang, Rothman, &amp; Cann (1998)</span>, editors of the journal Epidemiology, write that “we intend to discourage the reporting of <span class="math inline">\(P\)</span>-values in any context in which the confounded elements [effect size and precision] can be conveniently separated, either numerically, graphically, or otherwise” (p. 8).</p>
</div>
<div id="potential-answers-to-the-objection" class="section level2">
<h2>Potential answers to the objection</h2>
<div id="answer-1" class="section level3">
<h3>Answer 1</h3>
<p><em>Just because people find something difficult does not mean there is a problem with it or that it should be abandoned.</em> If we applied this objection to significance testing to other things, we would end up without many essential scientific tools. Take, for instance, logic: several highly-replicable results in cognitive psychology show that people have difficulties reasoning logically, at least in the abstract. <span class="citation">Wason (1966)</span> famously showed that people had great difficulty with his <a href="https://en.wikipedia.org/wiki/Wason_selection_task">card selection task</a>, which requires deductive reasoning. This does not make deductive reasoning any less valuable. Certainly we should not ask people to abandon deductive reasoning on this basis.</p>
<p>Likewise, probability itself is difficult for people to understand. Teachers of probability who introduce people to the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> know that even when shown the correct solution, many refuse to believe it. Probability may be a difficult topic, but abandoning probability reasoning would be a disaster for science.</p>
<p>Reasoning from <span class="math inline">\(p\)</span> values is, in fact, nothing more than reasoning about sampling distributions; abandoning <span class="math inline">\(p\)</span> values would be tantamount to abandoning reasoning from sampling distributions. If sampling distributions are an important concept to understand and use, then perhaps we should think about <span class="math inline">\(p\)</span> values like deductive reasoning and probability: yes, people have problems reasoning deductively and with probabilities. This makes the training of deductive reasoning and probability in science <em>even more</em> important, not less.</p>
<p>One could object that significance testing logic is itself flawed and not essential for scientific reasoning. If significance testing is flawed, then the objection that people have difficulty with significance testing is redundant. If significance testing is not flawed—and <em>particularly</em> if the underlying principle of evidence is important to science, as some argue—then the objection is impotent. Either way, the objection fails.</p>
</div>
<div id="answer-2" class="section level3">
<h3>Answer 2</h3>
<p><em>Misinterpretations and dichotomisation are not inherent to the logic of significance testing; the paradigm actually tells you the fallacies are problematic.</em></p>
</div>
<div id="answer-3" class="section level3">
<h3>Answer 3</h3>
<p><em>The actual import of the misunderstandings is unclear.</em></p>
<p>Misinterpretations may (in part) be driven by how they are probed; not clear how much effect they have in a research program</p>
<p>Misunderstandings involve explicit knowledge in abstract scenarios; often it is unclear how this actually plays out in research scenarios.</p>
<p>(but note that sometimes it is clear, when they actually change research conclusions)</p>
</div>
<div id="answer-4" class="section level3">
<h3>Answer 4</h3>
<p><em>Unclear that other approaches would be better, and certainly they do not have the same theoretical grounding.</em></p>
</div>
<div id="answer-5" class="section level3">
<h3>Answer 5</h3>
<p><em>Evidence for dichotomisation (in particular, cliff effect) often depends on a normative assumption; but what is it?</em></p>
</div>
<div id="answer-6" class="section level3">
<h3>Answer 6</h3>
<p>Upton Sinclair said that “[i]t is difficult to get a man to understand something, when his salary depends on his not understanding it.” Misunderstandings of significance testing appear opportunistic: researchers do not always dichotomise evidence or make fall into the fallacy of acceptance. If it suits them, they can often be quite nuanced about the interpretation of <span class="math inline">\(p\)</span> values. The concept of “marginal significance” is convenient when <span class="math inline">\(p\)</span> values do not quite reach typical thresholds and a researcher wants to show evidence for a particular effect.</p>
<p>This suggests that what is going wrong is not statistical significance <em>per se</em>, but rather opportunism potentially driven by incentives among scientists. Fallacies can be convenient. If one is faced with a mediocre <span class="math inline">\(p\)</span> value obtained with a small sample size, it is more convenient to fall into the fallacy of acceptance than to actually apply the logic of significance testing, which may tell you the evidence is modest and strong conclusions can’t be reached. As mentioned above, the logic of significance testing can actually tell you <em>why</em> this is a problem: unchecked opportunism makes it easy to find evidence for claims even when they are not true.</p>
</div>
<div id="answer-7" class="section level3">
<h3>Answer 7</h3>
<p><em>Fallacies are presented in textbooks by choice, because they are easier.</em> Pressures exist on those training students beyond just getting it right. One can hardly blame significance testing.</p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references hanging-indent">
<div id="ref-Cumming:2014">
<p>Cumming, G. (2014). The new statistics: Why and how. <em>Psychological Science</em>, <em>25</em>, 7–29.</p>
</div>
<div id="ref-Falk:Greenbaum:1995">
<p>Falk, R., &amp; Greenbaum, C. W. (1995). Significance tests die hard: The amazing persistence of a probabilistic misconception. <em>Theory &amp; Psychology</em>, <em>5</em>(1), 75–98. Retrieved from <a href="https://doi.org/10.1177/0959354395051004">https://doi.org/10.1177/0959354395051004</a></p>
</div>
<div id="ref-Fidler:Loftus:2009">
<p>Fidler, F., &amp; Loftus, G. R. (2009). Why figures with error bars should replace <span class="math inline">\(p\)</span> values: Some conceptual arguments and empirical demonstrations. <em>Zeitschrift Fūr Psychologie</em>, <em>217</em>(1), 27–37.</p>
</div>
<div id="ref-Gelman:Stern:2006">
<p>Gelman, A., &amp; Stern, H. (2006). The difference between “significant” and “not significant” is not itself statistically significant. <em>The American Statistician</em>, <em>60</em>(4), 328–331.</p>
</div>
<div id="ref-Gigerenzer:etal:2004">
<p>Gigerenzer, G., Krauss, S., &amp; Vitouch, O. (2004). The null ritual: What you always wanted to know about significance testing but were afraid to ask. In D. Kaplan (Ed.), <em>The Sage handbook of quantitative methodology for the social sciences</em>. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-Greenland:etal:2016">
<p>Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., &amp; Altman, D. G. (2016). Statistical tests, p values, confidence intervals, and power: A guide to misinterpretations. <em>European Journal of Epidemiology</em>, <em>31</em>(4), 337–350. Retrieved from <a href="https://doi.org/10.1007/s10654-016-0149-3">https://doi.org/10.1007/s10654-016-0149-3</a></p>
</div>
<div id="ref-Haller:Krauss:2002">
<p>Haller, H., &amp; Krauss, S. (2002). Misinterpretations of significance: A problem students share with their teachers? <em>Methods of Psychological Research Online</em>, <em>7</em>.</p>
</div>
<div id="ref-Lang:etal:1998">
<p>Lang, J. M., Rothman, K. J., &amp; Cann, C. I. (1998). That confounded P-value. <em>Epidemiology</em>, <em>9</em>(1), 7–8. Retrieved from <a href="insights.ovid.com">insights.ovid.com</a></p>
</div>
<div id="ref-McShane:Gal:2017">
<p>McShane, B. B., &amp; Gal, D. (2017). Statistical Significance and the Dichotomization of Evidence. <em>Journal of the American Statistical Association</em>, <em>112</em>(519), 885–895. Retrieved from <a href="https://doi.org/10.1080/01621459.2017.1289846">https://doi.org/10.1080/01621459.2017.1289846</a></p>
</div>
<div id="ref-Nieuwenhuis:etal:2011">
<p>Nieuwenhuis, S., Forstmann, B. U., &amp; Wagenmakers, E. J. (2011). Erroneous analyses of interactions in neuroscience: A problem of significance. <em>Nature Neuroscience</em>, <em>14</em>, 1105–1107.</p>
</div>
<div id="ref-Oakes:1986">
<p>Oakes, M. (1986). <em>Statistical inference: A commentary for the social and behavioral sciences</em>. Chichester: Wiley.</p>
</div>
<div id="ref-Rosenthal:Gaito:1963">
<p>Rosenthal, R., &amp; Gaito, J. (1963). The interpretation of levels of significance by psychological researchers. <em>The Journal of Psychology: Interdisciplinary and Applied</em>, <em>55</em>, 33–38.</p>
</div>
<div id="ref-Wason:1966">
<p>Wason, P. (1966). Reasoning. In B. M. Foss (Ed.), <em>New horizons in psychology</em> (Vol. 1). Harmondsworth: Penguin.</p>
</div>
</div>
</div>
